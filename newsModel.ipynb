{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca7b359-53ff-4973-a3d0-5546dab98466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0300bc-51b6-4dd5-b470-0974decfd589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article      Date  \\\n",
      "0  KARACHI: The Sindh government has decided to b...  1/1/2015   \n",
      "1  HONG KONG: Asian markets started 2015 on an up...  1/2/2015   \n",
      "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  1/5/2015   \n",
      "3  HONG KONG: Asian markets tumbled Tuesday follo...  1/6/2015   \n",
      "4  NEW YORK: US oil prices Monday slipped below $...  1/6/2015   \n",
      "\n",
      "                                             Heading  NewsType  \n",
      "0  sindh govt decides to cut public transport far...  business  \n",
      "1                    asia stocks up in new year trad  business  \n",
      "2           hong kong stocks open 0.66 percent lower  business  \n",
      "3             asian stocks sink euro near nine year   business  \n",
      "4                 us oil prices slip below 50 a barr  business  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Articles.csv', encoding='ISO-8859-1')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471d0191-057c-49e7-b015-eda1f5992985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['karachi the sindh government has decided to bring down public transport fares by per cent due to massive reduction in petroleum product prices by the federal government geo news reportedsources said reduction in fares will be applicable on public transport rickshaw taxi and other means of travelingmeanwhile karachi transport ittehad kti has refused to abide by the government decisionkti president irshad bukhari said the commuters are charged the lowest fares in karachi as compare to other parts of the country adding that pc vehicles run on compressed natural gas cng bukhari said karachi transporters will cut fares when decrease in cng prices will be made ', 'hong kong asian markets started on an upswing in limited trading on friday with mainland chinese stocks surging in hong kong on speculation beijing may ease monetary policy to boost slowing growthhong kong rose percent closing points higher at seoul closed up percent rising points to while sydney gained percent or points to close at singapore edged up percent gaining points to markets in mainland china japan taiwan new zealand the philippines and thailand remained closed for holidayswith mainland bourses shut until january shares in chinese developers and financial companies surged in hong kong stoked by hopes that beijing could ease monetary policy to support lagging growth in the worlds secondlargest economychina vanke the countrys biggest developer by sales leapt percent and the peoples insurance company group of china ltd was up percent in afternoon tradingtrainbuilders csr corp and china cnr corp soared csr by percent and china cnr by percent extending gains on december after they announced a merger agreementchinas manufacturing growth dropped in december to its lowest level of an official survey showed thursday as the sector struggles with weak domestic demandchinas official purchasing managers index pmi released by the national bureau of statistics nbs came in at last month down from recorded in novemberthe index which tracks activity in factories and workshops is considered a key indicator of the health of chinas economy a major driver of global growth a figure above signals expansion while anything below indicates contractiongrowth momentum is still insufficient nbs said in a statement investors eye us factory data on forex markets the dollar extended gains ahead of the release of american factory data due later on friday and following a steady stream of good news from the worlds biggest economythe dollar bought yen compared to yen in final trading on wednesdaywall street toasted a banner year in with us equity markets finishing near alltime highsthe euro meanwhile slipped amid growing expectations that the european central bank which meets on january will start buying sovereign bonds the single currency bought compared to in preholiday tradethe ecb has already used several tools to push inflation in member nations back up to the percent annual rate it regards as healthy including asset purchases and making cheap loans available to banksit is also examining the possibility of largescale purchases of sovereign debt socalled quantitative easing qe to help jumpstart the european unions moribund economyoil prices rose on friday with us benchmark west texas intermediate for february delivery rising cents to and brent crude for february gaining cents to the gains in asian trading are likely because of the positive us crude stockpiles data released on wednesday daniel ang investment analyst at phillip futures in singapore told afpus crude reserves fell by million barrels in the week to december the us energy information administration said in its last petroleum report for released on wednesday boosting prices that lost nearly half their value in the second half of the yearthere is growing speculation that the slide in global oil prices the biggest since the financial crisis in may have been excessiveif we do see some supplyside responses or even if theyre anticipated over the course of this first quarter of the year we might find that oil has in fact bottomed michael mccarthy a chief strategist at cmc markets in sydney told bloomberggold was at an ounce compared with in endofyear trading on wednesdayin other markets jakarta ended up percent or points at coal firm indo tambangraya megah gained percent to rupiah while miner aneka tambang slipped percent to rupiah malaysias main stock index shed percent or points to close at malayan banking lost percent to ringgit public bank slipped percent to while top globe added percent ringgit singapore rose percent or points to agribusiness company wilmar international gained percent to sg while real estate developer capitaland dipped percent to sg mumbai gained percent or points to end at housing development finance corp rose percent to rupees while mahindra mahindra fell percent to rupees afp ', 'hong kong hong kong shares opened percent lower monday following a tepid lead from wall street as the first full week of the new year kicked offthe benchmark hang seng index dipped points to ', 'hong kong asian markets tumbled tuesday following painful losses in new york and europe while the euro sat near nineyear lows as political uncertainty in greece fanned renewed fears it could leave the eurozoneoil prices which fell below the psychological a barrel mark in us trade edged up marginally but remained under pressure owing to a global supply glut weak demand and a stronger dollartokyo tumbled percent hong kong lost percent sydney eased percent seoul was percent lower while shanghai reversed earlier losses to gain percentthe first full week of the new year got off to a traumatic start for dealers as they bet a january general election in greece will see a victory for the the leftwing syriza partymarkets fear the party will roll back austerity measures required under the imfeu bailout of the country which could in turn lead it to exit the eurozonethe year is barely three trading days old and already the two biggest themes that were predicted to affect the markets this year are making headlines oversupply of commodities and the eurozone evan lucas a markets strategist in melbourne at ig ltd wrote in an email to clients according to bloomberg newsat the weekend der spiegel quoted german government sources as saying they consider greeces exit almost inevitable if syriza wins the snap pollchancellor angela merkel and finance minister wolfgang schaeuble had come to consider athens removal from the bloc would be manageable the magazine saidhowever investors were spooked and on monday greek stocks sank more than percent while the paris madrid and milan exchanges fell more than percent oil below a barrel the dow dived percent the sp fell percent and the nasdaq lost percentin currency trade the euro sank to monday its lowest level since march on tuesday morning the single currency recovered slightly buying the euro was meanwhile at yen against yen in us trade and well down from the yen fridayadding to downward pressure is increased speculation that the european central bank will buy eurozone government bonds to counter deflation risksthe dollar was at yen early tuesday compared with in new york monday and also well down from yen fridayoil prices were marginally up tuesday after slipping below for the first time in more than five years in new yorkus benchmark west texas intermediate for february delivery rose eight cents to while brent crude for february gained cents to wti tapped mondaythe cost of crude has plunged since june as supplies outstrip demand with key consumer china slowing down the eurozone struggling and the dollar in which it is priced strengtheninga decision late last year by the organization of the petroleum exporting countries opec to maintain output despite the glut has also cut into pricesthe fundamentals of oil are unlikely to change in the first half of this year which will see oil bedding down into its bear market for months to come igs lucas saidgold was at an ounce compared with on monday afp ', 'new york us oil prices monday slipped below a barrel for the first time in more than five years as the surging dollar and news of additional supplies extended a sixmonth routus benchmark west texas intermediate for february delivery in free fall since june ended at a barrel down or five percent the contract got as low as a barrel earlier in the session its lowest level since may european benchmark brent oil for february delivery fell to a barrel in londonmondays slide in oil prices followed indications of rising output from key producers russia and iraq at a time when forecasters have trimmed their demand projections due to weak global economic growththe breaching of the psychologically important level also came on a turbulent day for global financial markets us stocks fell nearly two percent approaching the drops in european equity markets as the euro plunged to a nineyear low on revived eurozone worriesa long rally in the greenback which gained percent last year against a basket of major currencies has weighed on the dollarpriced oil market by making crude more expensive for buyers using weaker currenciesoil prices could fall further still analysts saytheres serious concern the bottoms not in yet said kyle cooper managing partner at iaf advisors in houston basically everyone whos taken a stab at the bottom has been wrongoil prices attempted to stabilize during the last two weeks but the fundamentals remain weak said gene mcgillian broker and analyst at tradition energy the market is trying to come to a bottom it could be anybodys guess but it appears we still have more to gofawad razaqzada a technical analyst at forexcom said the drop below a barrel could trigger more selling paving the way for oil to fall as low as or a barrel in the coming weeksweak fundamentalsthe retreat in prices comes on the heels of a multiyear boom in us oil production that has shaken the global petroleum market and put the us in a league with oil giants russia and saudi arabiaother leading producers are also pumping aggressively iraqs oil ministry last week released figures showing that december crude exports reached their highest since meanwhile the organization of the petroleum exporting countries has consistently ruled out action despite the monthslong slide in pricesin november the cartel met in vienna and took no action as key powerbrokers like saudi arabian oil minister ali alnaimi said he preferred for the market to balance itself in december naimi told a middle east publication the group would take the same handsoff approach even if oil fell to a barrelmeanwhile economic growth remains uncertain in europe and in many emerging economies such as china and brazil the international energy agency in december projected global crude inventories could rise by nearly million barrels in the first six months of the agency also cut its demand outlook by more than barrels a day for energy equities by far the worst performing sector in the sp last year suffered more pain monday dow member chevron fell percent while oilservices giant schlumberger lost percentkey us oil companies like conocophillips and shale producer continental resources have cut their drilling budgets for still analysts expect us output to continue to rise this year owing to investments that have already been made that will put more pressure on crude pricesi still think one of the primary drivers of the market is us oil production and i really dont see us oil production growth slowing appreciably in the first quarter cooper said afp ']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = text.replace('\\r\\n', ' ').replace('\\n', ' ')  # Replace \\r\\n and \\n with a space\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "cleaned_articles = df['Article'].apply(clean_text).tolist()  # Apply clean_text to each article\n",
    "print(cleaned_articles[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b7f365-d568-46bf-acf3-7c7834836a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned articles have been saved to 'cleaned_articles.txt'.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Articles.csv\", encoding='ISO-8859-1') \n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = text.replace('\\r\\n', ' ').replace('\\n', ' ')  # Replace \\r\\n and \\n with a space\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "cleaned_articles = df['Article'].head(100).apply(clean_text).tolist()\n",
    "\n",
    "with open(\"cleaned_articles.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for article in cleaned_articles:\n",
    "        f.write(article + \"\\n\\n\")\n",
    "\n",
    "print(\"Cleaned articles have been saved to 'cleaned_articles.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b4179-c292-4c36-af95-f5ce32e56c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Set device to MPS, CUDA, or CPU\n",
    "device = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model components (Head, MultiHeadAttention, FeedForward, Block)\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd, context_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2, -1) * (C ** -0.5)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        return wei @ v\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, n_embd, context_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            Head(head_size, n_embd, context_size, dropout) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return self.dropout(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 2 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, context_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, context_size, dropout)\n",
    "        self.ffwd = FeedForward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=128, context_size=128, n_head=4, n_layer=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(context_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head, context_size, dropout) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "# Get batch function\n",
    "def get_batch(split, batch_size, context_size, train_data, val_data):\n",
    "    data_split = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data_split) - context_size, (batch_size,))\n",
    "    x = torch.stack([data_split[i:i + context_size] for i in ix])\n",
    "    y = torch.stack([data_split[i + 1:i + context_size + 1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "# Estimate loss function\n",
    "def estimate_loss(model, batch_size, context_size, eval_iters, train_data, val_data):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, batch_size, context_size, train_data, val_data)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean().item()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# Training loop\n",
    "def train(model, steps, batch_size, context_size, lr=3e-4, report_frequency=500, train_data, val_data, checkpoint_path=None):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for step in range(steps):\n",
    "        xb, yb = get_batch('train', batch_size, context_size, train_data, val_data)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss and monitor training/validation progress\n",
    "        if step % report_frequency == 0 or step == steps - 1:\n",
    "            losses = estimate_loss(model, batch_size, context_size, 100, train_data, val_data)\n",
    "            print(f\"Step {step}, train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if checkpoint_path:\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Model checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "# Text generation function\n",
    "def generate(model, start_idx, context_size, number_of_tokens, device, temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    idx = start_idx\n",
    "\n",
    "    for _ in range(number_of_tokens):\n",
    "        # Crop to last `context_size` tokens\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Forward pass: Get logits\n",
    "        logits, _ = model(idx_cond)\n",
    "        \n",
    "        # Apply softmax to logits to get probabilities (for sampling or argmax)\n",
    "        probs = F.softmax(logits[:, -1, :], dim=-1)  # Use only the last token's logits\n",
    "        \n",
    "        # Sample the next token (e.g., take the token with the highest probability)\n",
    "        next_token = torch.multinomial(probs, 1)  # Alternatively, use `torch.argmax(probs, dim=-1)`\n",
    "        \n",
    "        # Append the new token to the sequence\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "# Main function to parse arguments\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Train, Evaluate, and Generate with a Transformer Language Model\")\n",
    "    parser.add_argument('--input', type=str, help=\"Path to input text file\")\n",
    "    parser.add_argument('--train', action='store_true', help=\"Train the model\")\n",
    "    parser.add_argument('--eval', action='store_true', help=\"Generate text using a trained model\")\n",
    "    parser.add_argument('--checkpoint', type=str, help=\"Path to save/load model checkpoint\")\n",
    "    parser.add_argument('--context_size', type=int, default=128, help=\"Context size for the model\")\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help=\"Batch size for training\")\n",
    "    parser.add_argument('--steps', type=int, default=5000, help=\"Number of training steps\")\n",
    "    parser.add_argument('--n_tokens', type=int, default=500, help=\"Number of tokens to generate during evaluation\")\n",
    "    parser.add_argument('--temperature', type=float, default=1.0, help=\"Sampling temperature\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load the dataset\n",
    "    if args.input:\n",
    "        with open(args.input, \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        characters = sorted(list(set(text)))\n",
    "        vocab_size = len(characters)\n",
    "\n",
    "        char_to_idx = {ch: i for i, ch in enumerate(characters)}\n",
    "        idx_to_char = {i: ch for i, ch in enumerate(characters)}\n",
    "        encode = lambda s: [char_to_idx[c] for c in s]\n",
    "        decode = lambda l: ''.join([idx_to_char[i] for i in l])\n",
    "\n",
    "        data = torch.tensor(encode(text), dtype=torch.long)\n",
    "        n = int(len(data) * 0.9)\n",
    "        train_data = data[:n]\n",
    "        val_data = data[n:]\n",
    "    else:\n",
    "        print(\"No input dataset specified.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the model\n",
    "    model = TransformerLanguageModel(vocab_size, n_embd=128, context_size=args.context_size).to(device)\n",
    "\n",
    "    if args.train:\n",
    "        train(model, steps=args.steps, batch_size=args.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcd451-8d70-4121-a973-cd45f5a315a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "from torch import nn\n",
    "\n",
    "# Your existing imports, classes, and code\n",
    "device = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model and training classes (Head, MultiHeadAttention, FeedForward, Block, TransformerLanguageModel, etc.) as defined in your code\n",
    "\n",
    "# Argument parser for CLI\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"CLI for Transformer Language Model\")\n",
    "    \n",
    "    subparsers = parser.add_subparsers(dest=\"mode\")\n",
    "    \n",
    "    # Train Mode Arguments\n",
    "    train_parser = subparsers.add_parser(\"train\", help=\"Train the language model\")\n",
    "    train_parser.add_argument(\"--input\", type=str, required=True, help=\"Path to the input dataset (txt file)\")\n",
    "    train_parser.add_argument(\"--checkpoint_path\", type=str, required=True, help=\"Path to save the model checkpoint\")\n",
    "    train_parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size for training\")\n",
    "    train_parser.add_argument(\"--context_size\", type=int, default=128, help=\"Context size for the model\")\n",
    "    train_parser.add_argument(\"--n_embd\", type=int, default=128, help=\"Embedding size\")\n",
    "    train_parser.add_argument(\"--n_layer\", type=int, default=3, help=\"Number of layers\")\n",
    "    train_parser.add_argument(\"--n_head\", type=int, default=4, help=\"Number of attention heads\")\n",
    "    train_parser.add_argument(\"--steps\", type=int, default=5000, help=\"Number of training steps\")\n",
    "\n",
    "    # Eval Mode Arguments\n",
    "    eval_parser = subparsers.add_parser(\"eval\", help=\"Evaluate the language model\")\n",
    "    eval_parser.add_argument(\"--checkpoint_path\", type=str, required=True, help=\"Path to the model checkpoint\")\n",
    "    eval_parser.add_argument(\"--start_text\", type=str, required=True, help=\"Prompt to start generation\")\n",
    "    eval_parser.add_argument(\"--num_tokens\", type=int, default=500, help=\"Number of tokens to generate\")\n",
    "    eval_parser.add_argument(\"--temperature\", type=float, default=1.0, help=\"Sampling temperature\")\n",
    "    eval_parser.add_argument(\"--top_k\", type=int, default=10, help=\"Top-k sampling\")\n",
    "\n",
    "    # Parse arguments\n",
    "    return parser.parse_args()\n",
    "\n",
    "# Training function\n",
    "def train(model, steps, batch_size, context_size, report_frequency=500, checkpoint_path=None):\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    model.train()\n",
    "    for step in range(steps):\n",
    "        xb, yb = get_batch('train', batch_size, context_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss and monitor training/validation progress\n",
    "        if step % report_frequency == 0 or step == steps - 1:\n",
    "            losses = estimate_loss(model, batch_size, context_size)\n",
    "            print(f\"Step {step}, train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
    "            \n",
    "            if checkpoint_path:\n",
    "                torch.save(model.state_dict(), checkpoint_path)  # Save checkpoint\n",
    "\n",
    "# Model inference (evaluation)\n",
    "def evaluate(model, start_text, num_tokens, context_size, device, temperature=1.0, top_k=10):\n",
    "    start_idx = torch.tensor(encode(start_text), dtype=torch.long, device=device).unsqueeze(0)\n",
    "    generated_output = generate_with_temperature(model, start_idx, context_size, number_of_tokens=num_tokens, device=device, temperature=temperature, top_k=top_k)\n",
    "\n",
    "    generated_text = decode(generated_output[0].tolist())\n",
    "    print(generated_text)\n",
    "\n",
    "# Main function to handle CLI modes\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    \n",
    "    # Load dataset for training\n",
    "    if args.mode == \"train\":\n",
    "        with open(args.input, \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Preprocess dataset and initialize model\n",
    "        characters = sorted(list(set(text)))\n",
    "        vocab_size = len(characters)\n",
    "        char_to_idx = {ch: i for i, ch in enumerate(characters)}\n",
    "        idx_to_char = {i: ch for i, ch in enumerate(characters)}\n",
    "        encode = lambda s: [char_to_idx[c] for c in s]\n",
    "        decode = lambda l: ''.join([idx_to_char[i] for i in l])\n",
    "\n",
    "        data = torch.tensor(encode(text), dtype=torch.long)\n",
    "        n = int(len(data) * 0.9)\n",
    "        train_data = data[:n]\n",
    "        val_data = data[n:]\n",
    "\n",
    "        # Initialize model\n",
    "        model = TransformerLanguageModel(vocab_size=vocab_size, n_embd=args.n_embd, context_size=args.context_size, \n",
    "                                        n_head=args.n_head, n_layer=args.n_layer).to(device)\n",
    "        \n",
    "        # Train the model\n",
    "        train(model, steps=args.steps, batch_size=args.batch_size, context_size=args.context_size, \n",
    "              checkpoint_path=args.checkpoint_path)\n",
    "\n",
    "    # Evaluate mode\n",
    "    elif args.mode == \"eval\":\n",
    "        # Load trained model\n",
    "        model = TransformerLanguageModel(vocab_size=vocab_size, n_embd=128, context_size=128, n_head=4, n_layer=3).to(device)\n",
    "        model.load_state_dict(torch.load(args.checkpoint_path))\n",
    "\n",
    "        # Generate text\n",
    "        evaluate(model, args.start_text, args.num_tokens, args.context_size, device, args.temperature, args.top_k)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056bd17-0b7a-4a1f-a8b6-2d227c8dbfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30729f5a-3886-4c03-a777-8a980c92d2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1533859384.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python train_eval_model.py train --input /path/to/cleaned_articles.txt --checkpoint_path /path/to/save_model.pt --batch_size 64 --context_size 128 --n_embd 128 --n_layer 3 --n_head 4 --steps 5000\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python train_eval_model.py train --input /path/to/cleaned_articles.txt --checkpoint_path /path/to/save_model.pt --batch_size 64 --context_size 128 --n_embd 128 --n_layer 3 --n_head 4 --steps 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2853281d-0478-4601-8e86-13d624fed602",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2885245080.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python train_eval_model.py eval --checkpoint_path /path/to/save_model.pt --start_text \"Once upon a time\" --num_tokens 500 --temperature 1.2 --top_k 10\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python train_eval_model.py eval --checkpoint_path /path/to/save_model.pt --start_text \"Once upon a time\" --num_tokens 500 --temperature 1.2 --top_k 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fd2f62c-4baf-4832-98f7-fc82558fa0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\julliet nyaware\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\julliet nyaware\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julliet nyaware\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julliet nyaware\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.8.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\julliet nyaware\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/204.1 MB 11.7 MB/s eta 0:00:18\n",
      "    --------------------------------------- 4.5/204.1 MB 11.7 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 6.6/204.1 MB 10.6 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 9.2/204.1 MB 11.2 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 11.5/204.1 MB 11.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 14.2/204.1 MB 11.2 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 16.8/204.1 MB 11.4 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 19.1/204.1 MB 11.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 21.8/204.1 MB 11.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 24.1/204.1 MB 11.5 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 26.5/204.1 MB 11.4 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 29.1/204.1 MB 11.5 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 31.7/204.1 MB 11.5 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 34.1/204.1 MB 11.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 36.4/204.1 MB 11.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 39.1/204.1 MB 11.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 41.7/204.1 MB 11.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 44.0/204.1 MB 11.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 46.4/204.1 MB 11.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 49.0/204.1 MB 11.6 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 51.6/204.1 MB 11.6 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 54.3/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 56.6/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 58.7/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 61.1/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 63.7/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 66.3/204.1 MB 11.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 68.9/204.1 MB 11.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 71.3/204.1 MB 11.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 73.7/204.1 MB 11.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 76.3/204.1 MB 11.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 78.9/204.1 MB 11.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 81.5/204.1 MB 11.7 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 83.9/204.1 MB 11.7 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 86.5/204.1 MB 11.7 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 88.9/204.1 MB 11.7 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 91.5/204.1 MB 11.7 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 94.1/204.1 MB 11.7 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 96.7/204.1 MB 11.7 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 99.1/204.1 MB 11.7 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 101.7/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 104.1/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 106.7/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 109.3/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 111.7/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 114.0/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 116.7/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 118.5/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 121.1/204.1 MB 11.6 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 123.5/204.1 MB 11.6 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 125.8/204.1 MB 11.6 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 128.5/204.1 MB 11.6 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 131.1/204.1 MB 11.6 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 133.7/204.1 MB 11.6 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 136.3/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 138.7/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 141.3/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 143.9/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 146.5/204.1 MB 11.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 148.9/204.1 MB 11.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 151.5/204.1 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 153.9/204.1 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 156.5/204.1 MB 11.7 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 158.9/204.1 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 161.5/204.1 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 164.1/204.1 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 166.5/204.1 MB 11.7 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 168.8/204.1 MB 11.7 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 171.4/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 173.8/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 176.2/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 178.8/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 181.4/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.0/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.1/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 188.7/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 191.4/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 194.0/204.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.3/204.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.0/204.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.6/204.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.4/6.2 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, torch\n",
      "Successfully installed fsspec-2025.3.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80afc4f9-96ae-42ab-9a97-67755b392556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input INPUT] [--train TRAIN] [--epoch EPOCH] [--context_size CONTEXT_SIZE]\n",
      "                             [--batch_size BATCH_SIZE] [--n_embd N_EMBD] [--n_layer N_LAYER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Julliet Nyaware\\AppData\\Roaming\\jupyter\\runtime\\kernel-93e7c17f-c6a5-4c33-a0c1-43b8c0d11c37.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julliet Nyaware\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Function to define device (MPS, CUDA, CPU)\n",
    "device = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define model components (Head, MultiHeadAttention, FeedForward, Block)\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd, context_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2, -1) * (C ** -0.5)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        return wei @ v\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, n_embd, context_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            Head(head_size, n_embd, context_size, dropout) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return self.dropout(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 2 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, context_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, context_size, dropout)\n",
    "        self.ffwd = FeedForward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=128, context_size=128, n_head=4, n_layer=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(context_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head, context_size, dropout) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "# Get batch function\n",
    "def get_batch(split, batch_size, context_size, train_data, val_data):\n",
    "    data_split = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data_split) - context_size, (batch_size,))\n",
    "    x = torch.stack([data_split[i:i + context_size] for i in ix])\n",
    "    y = torch.stack([data_split[i + 1:i + context_size + 1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "# Estimate loss function\n",
    "def estimate_loss(model, batch_size, context_size, eval_iters=100, train_data=None, val_data=None):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, batch_size, context_size, train_data, val_data)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean().item()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# Train function\n",
    "def train(model, train_data, val_data, steps, batch_size, context_size, report_frequency=500):\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    model.train()\n",
    "    for step in range(steps):\n",
    "        xb, yb = get_batch('train', batch_size, context_size, train_data, val_data)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss and monitor training/validation progress\n",
    "        if step % report_frequency == 0 or step == steps - 1:\n",
    "            losses = estimate_loss(model, batch_size, context_size, train_data=train_data, val_data=val_data)\n",
    "            print(f\"Step {step}, train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
    "\n",
    "# Generate with temperature function\n",
    "def generate_with_temperature(model, start_idx, context_size, number_of_tokens, temperature=1.0, top_k=10):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    idx = start_idx\n",
    "\n",
    "    for _ in range(number_of_tokens):\n",
    "        # Crop to last `context_size` tokens\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Forward pass: Get logits\n",
    "        logits, _ = model(idx_cond)\n",
    "        \n",
    "        # Apply softmax to logits to get probabilities (for sampling or argmax)\n",
    "        logits = logits[:, -1, :] / temperature  # Scale the logits by temperature\n",
    "        probs = F.softmax(logits, dim=-1)  # Use only the last token's logits\n",
    "        \n",
    "        # Top-k sampling: Select the top-k probabilities and their corresponding tokens\n",
    "        top_probs, top_idx = probs.topk(top_k, dim=-1)\n",
    "        \n",
    "        # Normalize the top probabilities to sum to 1 (in case they don't)\n",
    "        top_probs = top_probs / top_probs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "        # Sample the next token from the top-k options using multinomial sampling\n",
    "        next_token = torch.multinomial(top_probs, 1)\n",
    "        \n",
    "        # Get the token corresponding to the sampled index from top_idx\n",
    "        next_token = top_idx.gather(-1, next_token)\n",
    "\n",
    "        # Append the new token to the sequence\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    characters = sorted(list(set(text)))\n",
    "    vocab_size = len(characters)\n",
    "\n",
    "    char_to_idx = {ch: i for i, ch in enumerate(characters)}\n",
    "    idx_to_char = {i: ch for i, ch in enumerate(characters)}\n",
    "    encode = lambda s: [char_to_idx[c] for c in s]\n",
    "    decode = lambda l: ''.join([idx_to_char[i] for i in l])\n",
    "\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "    n = int(len(data) * 0.9)\n",
    "    train_data = data[:n]\n",
    "    val_data = data[n:]\n",
    "\n",
    "    return train_data, val_data, vocab_size, decode\n",
    "\n",
    "# Main function for argument parsing and execution\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input', type=str, help='Path to the dataset file')\n",
    "    parser.add_argument('--train', type=str, help='Path to save the trained model checkpoint')\n",
    "    parser.add_argument('--epoch', type=int, default=100, help='Number of training epochs')\n",
    "    parser.add_argument('--context_size', type=int, default=128, help='Size of context window')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='Batch size')\n",
    "    parser.add_argument('--n_embd', type=int, default=128, help='Embedding size')\n",
    "    parser.add_argument('--n_layer', type=int, default=3, help='Number of layers in the transformer')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load data\n",
    "    train_data, val_data, vocab_size, decode = load_data(args.input)\n",
    "\n",
    "    # Initialize model\n",
    "    model = TransformerLanguageModel(vocab_size, n_embd=args.n_embd, context_size=args.context_size, n_layer=args.n_layer).to(device)\n",
    "\n",
    "    # Training mode\n",
    "    if args.train:\n",
    "        train(model, train_data, val_data, steps=args.epoch * len(train_data) // args.batch_size, batch_size=args.batch_size, context_size=args.context_size)\n",
    "        torch.save(model.state_dict(), args.train)\n",
    "        print(f\"Model saved to {args.train}\")\n",
    "\n",
    "    # Inference mode (evaluate and generate text)\n",
    "    if not args.train:\n",
    "        # Load trained model\n",
    "        model.load_state_dict(torch.load(args.train))\n",
    "        model.eval()\n",
    "        \n",
    "        start_idx = torch.zeros((1, 1), dtype=torch.long, device=device)  # Example start token\n",
    "        generated_output = generate_with_temperature(model, start_idx, args.context_size, number_of_tokens=500, temperature=1.2, top_k=10)\n",
    "        generated_text = decode(generated_output[0].tolist())\n",
    "        print(generated_text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
